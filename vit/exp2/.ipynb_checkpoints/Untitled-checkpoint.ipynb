{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "from collections.abc import Sequence\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import os\n",
    "\n",
    "def windowing(X_instants, R_instants, Y_instants, v_Hz=2000, window_time_s=.150, relative_overlap=.7, steady=True, steady_margin_s=1.5):\n",
    "    \"\"\"\n",
    "        steady=True, steady_margin_s=0 -> finestre dove sample tutti della stessa label (o solo movimento o solo rest)\n",
    "        steady=True, steady_margin_s=1.5 -> finestre dove tagli i primi e ultimi 1.5s di movimento\n",
    "        steady=False -> tutte le finestre, anche quelle accavallate tra movimento e rest\n",
    "    \"\"\"\n",
    "    \n",
    "    # Centro della finestra (numero di campioni)\n",
    "    #r = round((v_Hz * window_time_s - 1) / 2)\n",
    "    r = int((v_Hz * window_time_s) / 2)\n",
    "    # Ampiezza finestra\n",
    "    #N = 2 * r + 1\n",
    "    N = 2 * r\n",
    "    # Campioni fuori finestra da guardare per capire se steady\n",
    "    margin_samples = round(v_Hz * steady_margin_s)\n",
    "\n",
    "    overlap_pixels = round(v_Hz * relative_overlap * window_time_s)\n",
    "    slide = (N - overlap_pixels)\n",
    "    \n",
    "    M_instants, C = X_instants.shape\n",
    "    # M = Numero di finestre\n",
    "    M = (M_instants - N) // slide + 1\n",
    "    \n",
    "    # La label dovrebbe essere quello indicato nell'ultimo istante\n",
    "    #Y_windows = Y_instants[-1 + N : M_instants : slide]\n",
    "    Y_windows = Y_instants[r : M_instants - r : slide]\n",
    "    # La repetition è quello che viene indicato a metà della finestra\n",
    "    R_windows = R_instants[r : M_instants - r : slide]\n",
    "\n",
    "    X_windows = np.zeros((M, N, C))\n",
    "    is_steady_windows = np.zeros(M, dtype=bool)\n",
    "    for m in range(M):\n",
    "        c = r + m * slide # c is python-style\n",
    "        \n",
    "        #X_windows[m, :, :] = X_instants[c - r : c + r + 1, :]\n",
    "        X_windows[m, :, :] = X_instants[c - r : c + r, :]\n",
    "\n",
    "        if Y_instants[c] == 0: # rest position is not margined\n",
    "            #is_steady_windows[m] = len(set(Y_instants[c - r: c + r + 1])) == 1\n",
    "            is_steady_windows[m] = len(set(Y_instants[c - r: c + r])) == 1\n",
    "        else:\n",
    "            #is_steady_windows[m] = len(set(Y_instants[c - r - margin_samples : c + r + margin_samples + 1])) == 1\n",
    "            is_steady_windows[m] = len(set(Y_instants[c - r - margin_samples : c + r + margin_samples])) == 1\n",
    "    \n",
    "    if steady:\n",
    "        return X_windows[is_steady_windows], R_windows[is_steady_windows], Y_windows[is_steady_windows]\n",
    "    return X_windows, R_windows, Y_windows\n",
    "\n",
    "def read_session(filename):\n",
    "    annots = loadmat(filename)\n",
    "\n",
    "    X = annots['emg'][:, np.r_[0:8,10:16]]\n",
    "    R = annots['rerepetition'].squeeze()\n",
    "    y = annots['restimulus'].squeeze()\n",
    "\n",
    "    # Fix class numbering (id -> index)\n",
    "    y[y >= 3 ] -= 1\n",
    "    y[y >= (6 - 1)] -= 1\n",
    "    y[y >= (8 - 2)] -= 1\n",
    "    y[y >= (9 - 3)] -= 1\n",
    "\n",
    "    return X, R, y\n",
    "\n",
    "class DB6Session(Dataset):\n",
    "\n",
    "    def __init__(self, filename, n_classes='7+1', steady=True, minmax=False, **kwargs):\n",
    "        if str(n_classes) not in {'7+1', '7'}:\n",
    "            raise ValueError('Wrong n_classes')\n",
    "\n",
    "        X, R, y = read_session(filename)\n",
    "\n",
    "        self.X_min, self.X_max = None, None\n",
    "        if minmax == True:\n",
    "            self.X_min, self.X_max = X.min(axis=0), X.max(axis=0)\n",
    "        if isinstance(minmax, Sequence) and minmax[0] is not None:\n",
    "            self.X_min, self.X_max = minmax\n",
    "        if self.X_min is not None:\n",
    "            X_std = (X - self.X_min) / (self.X_max - self.X_min)\n",
    "            X_scaled = X_std * 2 - 1\n",
    "            X = X_scaled\n",
    "            print(\"minmax\", self.X_min, self.X_max)\n",
    "        \n",
    "        X_windows, R_windows, Y_windows = windowing(X, R, y, steady=steady, **kwargs)\n",
    "\n",
    "        if n_classes == '7':\n",
    "            # Filtra via finestre di non movimento\n",
    "            mask = Y_windows != 0\n",
    "            X_windows, R_windows, Y_windows = X_windows[mask], R_windows[mask], Y_windows[mask]\n",
    "\n",
    "            # Rimappa label da 1-7 a 0-6\n",
    "            Y_windows -= 1\n",
    "\n",
    "        self.X = torch.tensor(X_windows, dtype=torch.float32).permute(0, 2, 1).unsqueeze(dim=2)\n",
    "        self.Y = torch.tensor(Y_windows, dtype=torch.long)\n",
    "        self.R = R_windows\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "\n",
    "    def split(self, total_folds, val_fold=0):\n",
    "        indices = np.arange(self.R.shape[0])\n",
    "        train_mask = self.R % total_folds != val_fold\n",
    "        return Subset(self, indices[train_mask]), Subset(self, indices[~train_mask])\n",
    "\n",
    "    def split_0(self, total_folds, val_fold=0):\n",
    "        indices = np.arange(self.R.shape[0])\n",
    "        train_mask = self.R % total_folds != val_fold\n",
    "        train_indices = indices[train_mask]\n",
    "        val_indices = indices[~train_mask]\n",
    "\n",
    "        train_indices_y = self[train_indices][1]\n",
    "        train_indices_y0 = train_indices[train_indices_y == 0]\n",
    "        train_indices_y1 = train_indices[train_indices_y != 0]\n",
    "        sample_count_per_class_avg = len(train_indices_y1) // 7\n",
    "        train_indices_y0 = resample(train_indices_y0, n_samples=sample_count_per_class_avg, replace=False)\n",
    "        train_indices = np.concatenate([train_indices_y0, train_indices_y1], axis=0)\n",
    "\n",
    "        return Subset(self, train_indices), Subset(self, val_indices)\n",
    "\n",
    "    def split_1(self, total_folds, val_fold=0):\n",
    "        indices = np.arange(self.R.shape[0])\n",
    "        train_mask = self.R % total_folds != val_fold\n",
    "        train_indices = indices[train_mask]\n",
    "        val_indices = indices[~train_mask]\n",
    "\n",
    "        train_indices_y = self[train_indices][1]\n",
    "        train_indices_y0 = train_indices[train_indices_y == 0]\n",
    "        train_indices_y1 = train_indices[train_indices_y != 0]\n",
    "        train_indices_y1 = resample(train_indices_y1, n_samples=len(train_indices_y0) * 7, replace=True)\n",
    "        train_indices = np.concatenate([train_indices_y0, train_indices_y1], axis=0)\n",
    "\n",
    "        return Subset(self, train_indices), Subset(self, val_indices)\n",
    "    \n",
    "class SuperSet(Dataset):\n",
    "\n",
    "    def __init__(self, *datasets):\n",
    "        self.datasets = datasets\n",
    "        self.lens = np.cumsum([0] + list(map(len, self.datasets)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataset_idx = int(np.argwhere(self.lens > idx)[0]) - 1\n",
    "        idx = idx - self.lens[dataset_idx]\n",
    "        return self.datasets[dataset_idx][idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.lens[-1]\n",
    "    \n",
    "class DB6MultiSession(SuperSet):\n",
    "\n",
    "    def __init__(self, subject, sessions, folder='.', **kwargs):\n",
    "        self.sessions = [DB6Session(os.path.join(folder, f'S{subject}_D{(i // 2) + 1}_T{(i % 2) + 1}.mat'), **kwargs) for i in sessions]\n",
    "        super().__init__(*self.sessions)\n",
    "\n",
    "    def split(self, total_folds, val_fold=0):\n",
    "        train_splits, val_splits = [], []\n",
    "        for train_split, val_split in map(lambda x: x.split(total_folds=total_folds, val_fold=val_fold), self.sessions):\n",
    "            train_splits.append(train_split)\n",
    "            val_splits.append(val_split)\n",
    "\n",
    "        return SuperSet(*train_splits), SuperSet(*val_splits)\n",
    "\n",
    "    def split_0(self, total_folds, val_fold=0):\n",
    "        train_splits, val_splits = [], []\n",
    "        for train_split, val_split in map(lambda x: x.split_0(total_folds=total_folds, val_fold=val_fold), self.sessions):\n",
    "            train_splits.append(train_split)\n",
    "            val_splits.append(val_split)\n",
    "\n",
    "        return SuperSet(*train_splits), SuperSet(*val_splits)\n",
    "\n",
    "    def split_1(self, total_folds, val_fold=0):\n",
    "        train_splits, val_splits = [], []\n",
    "        for train_split, val_split in map(lambda x: x.split_1(total_folds=total_folds, val_fold=val_fold), self.sessions):\n",
    "            train_splits.append(train_split)\n",
    "            val_splits.append(val_split)\n",
    "\n",
    "        return SuperSet(*train_splits), SuperSet(*val_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax [-5.04863972e-04 -3.71088739e-04 -1.26357729e-04 -9.77940726e-05\n",
      " -8.86311100e-05 -2.18426168e-04 -2.09364778e-04 -1.08514459e-05\n",
      " -7.00831413e-04 -2.00893322e-04 -1.02204438e-04 -6.16701509e-05\n",
      " -1.18733544e-04 -1.48412204e-04] [1.29621930e-03 3.13192722e-04 1.38760413e-04 1.38142030e-04\n",
      " 8.10787387e-05 1.94143475e-04 1.27040956e-04 7.61724368e-06\n",
      " 5.01827104e-04 2.91279517e-04 1.90823819e-04 1.19949276e-04\n",
      " 1.47030325e-04 1.46943945e-04]\n",
      "minmax [-5.04863972e-04 -3.71088739e-04 -1.26357729e-04 -9.77940726e-05\n",
      " -8.86311100e-05 -2.18426168e-04 -2.09364778e-04 -1.08514459e-05\n",
      " -7.00831413e-04 -2.00893322e-04 -1.02204438e-04 -6.16701509e-05\n",
      " -1.18733544e-04 -1.48412204e-04] [1.29621930e-03 3.13192722e-04 1.38760413e-04 1.38142030e-04\n",
      " 8.10787387e-05 1.94143475e-04 1.27040956e-04 7.61724368e-06\n",
      " 5.01827104e-04 2.91279517e-04 1.90823819e-04 1.19949276e-04\n",
      " 1.47030325e-04 1.46943945e-04]\n"
     ]
    }
   ],
   "source": [
    "train = DB6MultiSession(folder='dataset_DB6', subject=1, sessions=[0,], minmax=True)\n",
    "test = DB6MultiSession(folder='dataset_DB6', subject=1, sessions=[3], minmax=(train.sessions[0].X_min, train.sessions[0].X_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 1, 300])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if './master-thesis/src' not in sys.path:\n",
    "    sys.path.append('./master-thesis/src')\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.db6 import DB6MultiSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax [-5.04863972e-04 -3.71088739e-04 -1.26357729e-04 -9.77940726e-05\n",
      " -8.86311100e-05 -2.18426168e-04 -2.09364778e-04 -1.08514459e-05\n",
      " -7.00831413e-04 -2.00893322e-04 -1.02204438e-04 -6.16701509e-05\n",
      " -1.18733544e-04 -1.48412204e-04] [1.29621930e-03 3.13192722e-04 1.38760413e-04 1.38142030e-04\n",
      " 8.10787387e-05 1.94143475e-04 1.27040956e-04 7.61724368e-06\n",
      " 5.01827104e-04 2.91279517e-04 1.90823819e-04 1.19949276e-04\n",
      " 1.47030325e-04 1.46943945e-04]\n",
      "minmax [-5.04863972e-04 -3.71088739e-04 -1.26357729e-04 -9.77940726e-05\n",
      " -8.86311100e-05 -2.18426168e-04 -2.09364778e-04 -1.08514459e-05\n",
      " -7.00831413e-04 -2.00893322e-04 -1.02204438e-04 -6.16701509e-05\n",
      " -1.18733544e-04 -1.48412204e-04] [1.29621930e-03 3.13192722e-04 1.38760413e-04 1.38142030e-04\n",
      " 8.10787387e-05 1.94143475e-04 1.27040956e-04 7.61724368e-06\n",
      " 5.01827104e-04 2.91279517e-04 1.90823819e-04 1.19949276e-04\n",
      " 1.47030325e-04 1.46943945e-04]\n"
     ]
    }
   ],
   "source": [
    "train_ = DB6MultiSession(folder='dataset_DB6', subject=1, sessions=[0,], minmax=True, image_like_shape=True)\n",
    "test_ = DB6MultiSession(folder='dataset_DB6', subject=1, sessions=[3], minmax=(train_.X_min, train_.X_max), image_like_shape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train[1000][0] != train_[1000][0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Formula: https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d\n",
    "def get_conv_output_size(input_size, kernel_size, stride=1, padding=0, dilation=1, **ignore):\n",
    "    tuple_to_int = lambda x: int(x[0]) if isinstance(x, tuple) else int(x)\n",
    "    kernel_size, stride, padding, dilation = tuple_to_int(kernel_size), tuple_to_int(stride), tuple_to_int(padding), tuple_to_int(dilation)\n",
    "    return int( ( (input_size + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1 )\n",
    "\n",
    "class TEMPONet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes, input_size=300, input_channels=14):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 32, 3, dilation=2, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 32, 3, dilation=2, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, 5, stride=1, padding=2),\n",
    "            torch.nn.AvgPool1d(2, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 64, 3, dilation=4, padding=4),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, 3, dilation=4, padding=4),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, 5, stride=2, padding=2),\n",
    "            torch.nn.AvgPool1d(2, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, 3, dilation=8, padding=8),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, 3, dilation=8, padding=8),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, 5, stride=4, padding=2),\n",
    "            torch.nn.AvgPool1d(2, stride=2, padding=0),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        def get_fc_input_size():\n",
    "            is_layer_conv = lambda x: isinstance(x, nn.Conv1d) or isinstance(x, nn.AvgPool1d)\n",
    "            layers = list(filter(is_layer_conv, [*self.conv1, *self.conv2, *self.conv3]))\n",
    "            \n",
    "            output_size = input_size\n",
    "            last_layer_output_planes = 1\n",
    "            for layer in layers:\n",
    "                output_size = get_conv_output_size(output_size, **vars(layer))\n",
    "                last_layer_output_planes = layer.out_channels if hasattr(layer, \"out_channels\") else last_layer_output_planes\n",
    "            \n",
    "            return output_size * last_layer_output_planes\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(get_fc_input_size(), 256), # input=640\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(128, n_classes),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = x.flatten(1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(net.conv1[6], \"out_channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool1d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.TEMPONet'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\n",
      "16.028672\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "net = TEMPONet(8)\n",
    "net.train(False)\n",
    "macs, params = profile(net, inputs=(torch.randn(1, 14, 300), ))\n",
    "print()\n",
    "print(macs / 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "        )\n",
    "\n",
    "        #self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.empty(1, num_patches, dim))\n",
    "        #nn.init.kaiming_uniform_(self.pos_embedding, a=5 ** .5)\n",
    "        nn.init.normal_(self.pos_embedding, std=.02)\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        #cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
    "        #x = torch.cat((cls_tokens, x), dim=1)\n",
    "        #x += self.pos_embedding[:, :(n + 1)]\n",
    "        x += self.pos_embedding\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "        \n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        x = self.mlp_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ViT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f026e0456d84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthop\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m net = ViT(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ViT' is not defined"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "net = ViT(\n",
    "    image_size = (1, 300),\n",
    "    patch_size = (1, 20),\n",
    "    channels = 14,\n",
    "    num_classes = 8,\n",
    "    dim = 300,\n",
    "    depth = 3,\n",
    "    heads = 3,\n",
    "    mlp_dim = 300,\n",
    "    dropout = .2,\n",
    "    emb_dropout = 0,\n",
    "    #pool = 'mean',\n",
    ")\n",
    "\n",
    "net.train(False)\n",
    "macs, params = profile(net, inputs=(torch.randn(1, 14, 1, 300), ))\n",
    "print()\n",
    "print(macs / 1e6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
